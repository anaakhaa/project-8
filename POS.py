import stanza

# List of 19 languages (ISO 639-1 codes) excluding Russian
languages = [
    "en", "es", "de", "fr", "it", "nl", "pt", "zh", "hi",
    "ar", "ja", "ko", "tr", "sv", "fi", "pl", "cs", "el", "he"
]

# Download language models
for lang in languages:
    stanza.download(lang)

# Load NLP pipelines for all languages
nlp_models = {lang: stanza.Pipeline(lang=lang, processors="tokenize,pos") for lang in languages}

# Example multilingual texts
texts = {
    "en": "Elon Musk founded SpaceX in 2002.",
    "es": "El gato negro corre rÃ¡pido.",
    "de": "Angela Merkel war die Kanzlerin von Deutschland.",
    "fr": "Emmanuel Macron est le prÃ©sident de la France.",
    "it": "Roma Ã¨ la capitale d'Italia.",
    "nl": "Amsterdam is de hoofdstad van Nederland.",
    "pt": "Cristiano Ronaldo Ã© um jogador de futebol famoso.",
    "zh": "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ã€‚",
    "hi": "à¤®à¤¹à¤¾à¤¤à¥à¤®à¤¾ à¤—à¤¾à¤‚à¤§à¥€ à¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¤ªà¤¿à¤¤à¤¾ à¤¥à¥‡à¥¤",
    "ar": "Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±.",
    "ja": "æ±äº¬ã¯æ—¥æœ¬ã®é¦–éƒ½ã§ã™ã€‚",
    "ko": "ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤.",
    "tr": "Ä°stanbul, TÃ¼rkiye'nin en bÃ¼yÃ¼k ÅŸehridir.",
    "sv": "Stockholm Ã¤r Sveriges huvudstad.",
    "fi": "Helsinki on Suomen pÃ¤Ã¤kaupunki.",
    "pl": "Warszawa jest stolicÄ… Polski.",
    "cs": "Praha je hlavnÃ­ mÄ›sto ÄŒeskÃ© republiky.",
    "el": "Î— Î‘Î¸Î®Î½Î± ÎµÎ¯Î½Î±Î¹ Î· Ï€ÏÏ‰Ï„ÎµÏÎ¿Ï…ÏƒÎ± Ï„Î·Ï‚ Î•Î»Î»Î¬Î´Î±Ï‚.",
    "he": "×™×¨×•×©×œ×™× ×”×™× ×‘×™×¨×ª ×™×©×¨××œ."
}

# Function to display POS tagging results
def display_results(doc, lang):
    print(f"\nğŸ” {lang.upper()} POS Tagging Results:")
    for sentence in doc.sentences:
        for word in sentence.words:
            print(f"Word: {word.text} | POS: {word.upos} | Dependency: {word.deprel}")

# Process and display results for all 19 languages
for lang, text in texts.items():
    doc = nlp_models[lang](text)
    display_results(doc, lang)
